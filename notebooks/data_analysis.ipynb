{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c5a5650",
   "metadata": {},
   "source": [
    "# CICIDDOS2019 Dataset Analysis\n",
    "## Phase 2: Data Exploration and Preprocessing\n",
    "\n",
    "This notebook provides comprehensive analysis of the CICIDDOS2019 dataset for our federated learning DDoS detection project.\n",
    "\n",
    "### Objectives:\n",
    "1. Load and explore the CICIDDOS2019 dataset\n",
    "2. Perform data cleaning and preprocessing\n",
    "3. Analyze features and their relevance for DDoS detection\n",
    "4. Visualize data distributions and attack patterns\n",
    "5. Prepare data for federated learning simulation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28309a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Custom modules\n",
    "from data.data_loader import CICDDoS2019Loader\n",
    "from data.preprocessing import DataPreprocessor\n",
    "from data.federated_split import FederatedDataDistributor\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094609d3",
   "metadata": {},
   "source": [
    "## 1. Load CICIDDOS2019 Dataset\n",
    "\n",
    "Let's start by loading the dataset and exploring its basic structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d915b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = CICDDoS2019Loader(data_path=\"../data/raw/CSV-01-12/01-12\")\n",
    "\n",
    "# Get dataset information\n",
    "print(\"ðŸ“Š CICIDDOS2019 Dataset Information\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "info = loader.get_dataset_info()\n",
    "print(f\"Total files: {info['total_files']}\")\n",
    "print(f\"Attack types: {len(info['attack_types'])}\")\n",
    "print(\"\\nFile sizes:\")\n",
    "total_records = 0\n",
    "for filename, size in info['file_sizes'].items():\n",
    "    print(f\"  {filename}: {size:,} records\")\n",
    "    total_records += size\n",
    "\n",
    "print(f\"\\nTotal records across all files: {total_records:,}\")\n",
    "\n",
    "# Load a sample for initial exploration (1000 records per file to start)\n",
    "print(\"\\nðŸ”„ Loading sample data...\")\n",
    "sample_df = loader.load_all_data(sample_size=1000)\n",
    "print(f\"Sample dataset loaded: {sample_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade1e5d",
   "metadata": {},
   "source": [
    "## 2. Explore Dataset Structure\n",
    "\n",
    "Let's examine the dataset structure in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfde438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"ðŸ” Dataset Structure Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {sample_df.shape}\")\n",
    "print(f\"Columns: {len(sample_df.columns)}\")\n",
    "print(f\"Memory usage: {sample_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\nðŸ“‹ Column Information:\")\n",
    "print(\"-\" * 30)\n",
    "for i, col in enumerate(sample_df.columns):\n",
    "    print(f\"{i+1:2d}. {col}\")\n",
    "\n",
    "print(\"\\nðŸ“Š Data Types:\")\n",
    "print(\"-\" * 20)\n",
    "print(sample_df.dtypes.value_counts())\n",
    "\n",
    "print(\"\\nðŸŽ¯ Target Variable Distribution:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Label distribution:\")\n",
    "print(sample_df['Label'].value_counts())\n",
    "print(\"\\nBinary label distribution:\")\n",
    "print(sample_df['Binary_Label'].value_counts())\n",
    "print(f\"Attack ratio: {sample_df['Binary_Label'].mean():.2%}\")\n",
    "\n",
    "print(\"\\nðŸ” Missing Values:\")\n",
    "print(\"-\" * 20)\n",
    "missing_data = sample_df.isnull().sum()\n",
    "missing_percent = 100 * missing_data / len(sample_df)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Percentage': missing_percent\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "# Show only columns with missing values\n",
    "if missing_df['Missing Count'].sum() > 0:\n",
    "    print(missing_df[missing_df['Missing Count'] > 0])\n",
    "else:\n",
    "    print(\"âœ… No missing values found!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
